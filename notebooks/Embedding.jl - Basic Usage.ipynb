{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7047f64d-36de-444f-9e75-9039020dedac",
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"../src/Juissie.jl\")\n",
    "using .Juissie"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e8925c-e357-4ca0-a2fd-bf4e693a10e5",
   "metadata": {},
   "source": [
    "## Embedding.jl\n",
    "\n",
    "The Embedding package contains the `Embedder` struct and some support functions for it. An `Embedder` is simply a wrapper for the embedding model and the tokenizer associated with that model.\n",
    "\n",
    "The embedding model will take a human readable string, and convert it into a neural network representation of that string. Effectively, this neural network representation is the output of the hidden state of the embedding model, more concretely a matrix of floats. With a sufficiently trained embedding model, two \"semantically similar\" strings will have similar embedding values. Or in other words, the distance between two embeddings in N-Dimensional space will be relatively small. \n",
    "\n",
    "For a simple example, the string \"Dog\" and \"Hound\" would probably have proximal embedding values, while the string \"Dog\" and \"business card\" would have more distant embedding values. \n",
    "\n",
    "### Initialize the Embedder struct\n",
    "\n",
    "The `Embedder` struct takes a hugging face model name. This model will be downloaded from hugging face, and initialized via the `HuggingFace` external package. This will provide the `model` and it's associated `tokenizer` which are both saved into the `Embedder`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "212a06d5-9a30-40e5-972c-673406af468f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "embedder = Embedder(\"BAAI/bge-small-en-v1.5\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfe4af8-3a68-4a27-a298-1a5f47df41f3",
   "metadata": {},
   "source": [
    "### Generate embedding for a provided text\n",
    "\n",
    "To convert a human readable text into a model's embedding, simply use the `embed(...)` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45f52d1f-c81e-4546-94d9-0a83bc89bb79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7871117\n",
      "0.5119946\n"
     ]
    }
   ],
   "source": [
    "text = \"This is sample text for testing\"\n",
    "embedding = embed(embedder, text)\n",
    "\n",
    "embedding_dog = embed(embedder, \"dog\")\n",
    "embedding_hound = embed(embedder, \"hound\")\n",
    "embedding_other = embed(embedder, \"busines card\")\n",
    "\n",
    "# calculate the cosine similarity\n",
    "dog_to_hound = cosine_similarity(embedding_dog, embedding_hound)\n",
    "dog_to_other = cosine_similarity(embedding_dog, embedding_other)\n",
    "\n",
    "# higher is better\n",
    "println(dog_to_hound)  # 0.7871117\n",
    "println(dog_to_other)  # 0.5119946"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d637f6-1489-4524-8fca-d919508cf2e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.0",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
